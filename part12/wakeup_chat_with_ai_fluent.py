import pvporcupine
import pyaudio
import struct
import configparser
from datetime import datetime

import asyncio
import threading
import time
from pathlib import Path
# æ¥è‡ªå‰é¢ç¤ºä¾‹
from voice_assistant.tasks.task_manager4 import AudioScheduler, PlayMusicTask
from voice_assistant.tasks.weather_task2 import WeatherTask
from voice_assistant.tasks.play_audio_task import PlayAudioTask
from voice_assistant.tasks.llm_task import LLMConversationTask


# nul parser
from voice_assistant.nlu.nlu import CommandParser
import webrtcvad

from voice_assistant.recognize_speech import recognize_speech

# config parser
config = configparser.ConfigParser()
# load config
config.read('../env/config.ini')

porcupine_access_key = config.get('listener', 'pvporcupine_access_key') # key

custom_keyword_franky_path = config.get('listener', 'custom_keyword_franky')

confirm_mp3_path = config.get('listener', 'confirm_mp3_path')


porcupine = pvporcupine.create(keyword_paths=[custom_keyword_franky_path],
                               keywords=["franky"],
                               access_key=porcupine_access_key,
                               sensitivities=[0.7])

pa = pyaudio.PyAudio()

audio_stream = pa.open(
    rate=porcupine.sample_rate,
    channels=1,
    format=pyaudio.paInt16,
    input=True,
    frames_per_buffer=porcupine.frame_length)


VAD = webrtcvad.Vad(2)      # â€˜2â€™ æ˜¯ aggressiveness (0â€“3)ï¼Œè¶Šé«˜è¶Šå®¹æ˜“åˆ¤ä¸ºâ€œè¯­éŸ³â€
SAMPLE_RATE = 16000
FRAME_DURATION = 30        # ms
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION / 1000) * 2  # bytesï¼Œå› ä¸ºæ˜¯ 16-bit

SILENCE_TIMEOUT = 1.2      # è¶…è¿‡ 1.2s æ— è¯­éŸ³ï¼Œç»“æŸä¼šè¯

def is_voice(frame_bytes):
    """webrtcvad è¦æ±‚ 16kHz 16bit å•å£°é“çš„åŸå§‹ PCM"""
    return VAD.is_speech(frame_bytes, SAMPLE_RATE)


def wake_and_recognize(loop: asyncio.AbstractEventLoop, scheduler: AudioScheduler):
    print("Listening for 'picovoice'...")
    nlu_parser = CommandParser()

    in_chat_session = False
    chat_session_history = []
    last_chat_task = None

    try:
        while True:
            pcm = audio_stream.read(porcupine.frame_length, exception_on_overflow=False)
            pcm = struct.unpack_from("h" * porcupine.frame_length, pcm)

            result = porcupine.process(pcm)

            if result >= 0 and not in_chat_session:
                # è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´
                now = datetime.now()
                # æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²
                formatted_date = now.strftime("%Y-%m-%d %H:%M:%S")
                print(f'ğŸ””{formatted_date} å”¤é†’è¯æ£€æµ‹åˆ°ï¼æ‰§è¡Œå”¤é†’åŠ¨ä½œ...')

                in_chat_session = True
                chat_session_history = []
                confirm_mp3 = Path(confirm_mp3_path)
                _was_playing = scheduler.audio_player.play_obj and scheduler.audio_player.play_obj.is_playing()
                print(f"_was_playing: {_was_playing}")
                loop.call_soon_threadsafe(
                    scheduler.enqueue,
                    PlayAudioTask(confirm_mp3, was_playing=_was_playing)
                )
                print(f'ğŸ””in_chat_session: {in_chat_session} å¯¹è¯sessionæ ‡è®°')
                continue

            if in_chat_session:
                from voice_assistant.recognize_speech.recognize_speech import recoginze_speech
                recognized_command = recoginze_speech(audio_stream, timeout=3)
                print(f"ğŸ—£ï¸ è¯†åˆ«åˆ°: {recognized_command!r}")

                if not recognized_command:
                    # in_chat_session = False
                    continue

                # 2) call NLU
                intent, params = nlu_parser.parse(recognized_command)
                print(f"ğŸ” è¯†åˆ«æ„å›¾ï¼šIntent={intent}, Params={params}")


                # è°ƒç”¨ä½ åŠ©æ‰‹çš„ä¸»é€»è¾‘æ¨¡å—
                # ç®€å•å‘½ä»¤è§£æ â€”â€” æ’­æ”¾éŸ³ä¹
                text = recognized_command
                chat_session_history.append({"role": "user", "content": text})

                if intent == "chat_with_ai":
                    # å…ˆå–æ¶ˆä¸Šä¸€æ¬¡çš„èŠå¤©ä»»åŠ¡ï¼ˆå¦‚æœå®ƒè¿˜åœ¨è·‘æˆ–åœ¨é˜Ÿåˆ—ï¼‰
                    if last_chat_task is not None:
                        loop.call_soon_threadsafe(scheduler.cancel_task, last_chat_task)
                    # ç„¶ååˆ›å»ºå¹¶å…¥é˜Ÿæ–°çš„èŠå¤©ä»»åŠ¡
                    new_task = LLMConversationTask([{"role": "user", "content": chat_session_history.copy()}])
                    last_chat_task = new_task
                    loop.call_soon_threadsafe(scheduler.enqueue, new_task)
                    # å°† LLM å¯¹è¯ä»»åŠ¡æ³¨å…¥
                    # loop.call_soon_threadsafe(scheduler.enqueue, LLMConversationTask(chat_session_history.copy()))
                    continue

                if intent == "play_music":
                    # åœ¨ asyncio è°ƒåº¦å™¨ä¸­åˆ›å»ºä»»åŠ¡
                    # å®‰å…¨åœ°æŠŠ MusicTask åŠ å…¥ä¸»çº¿ç¨‹çš„ asyncio è°ƒåº¦å™¨
                    loop.call_soon_threadsafe(scheduler.enqueue, PlayMusicTask())
                elif intent == "pause_music":
                    # åœ¨ä¸»å¾ªç¯é‡Œåˆ›å»ºä¸€ä¸ª pause() çš„åç¨‹ä»»åŠ¡
                    # ç›´æ¥æš‚åœæ’­æ”¾å™¨
                    loop.call_soon_threadsafe(scheduler.pause_music)
                elif intent == "resume_music":
                    loop.call_soon_threadsafe(scheduler.resume_music)
                elif intent == "next_track":
                    loop.call_soon_threadsafe(scheduler.next_track)
                elif intent == "prev_track":
                    loop.call_soon_threadsafe(scheduler.prev_track)
                elif intent == "stop_music":
                    # åœæ‰ä»»åŠ¡å¹¶åœæ­¢æ’­æ”¾å™¨
                    loop.call_soon_threadsafe(scheduler.audio_player.pause_music)

                elif intent == "weather":
                    # å°† WeatherTask åŠ å…¥è°ƒåº¦å™¨
                    was_playing = scheduler.audio_player.play_obj and scheduler.audio_player.play_obj.is_playing()
                    print(f"was_playing: {was_playing}")
                    loop.call_soon_threadsafe(
                        scheduler.enqueue,
                        WeatherTask(was_playing=was_playing)
                    )
                time.sleep(1)

    except KeyboardInterrupt:
        print("å…³é—­ä¸­...")

    finally:
        audio_stream.stop_stream()
        audio_stream.close()
        pa.terminate()
        porcupine.delete()


# === 5. å¯åŠ¨ ===
async def main():
    scheduler = AudioScheduler(mp3_dir=Path("../voice_assistant/mp3s"), loop_playlist=True)
    # å¯åŠ¨è°ƒåº¦å™¨å¾ªç¯
    asyncio.create_task(scheduler.loop())

    # è·å–å½“å‰äº‹ä»¶å¾ªç¯å¹¶ä¼ å…¥è¯†åˆ«çº¿ç¨‹
    loop = asyncio.get_running_loop()
    threading.Thread(target=wake_and_recognize, args=(loop, scheduler), daemon=True).start()

    # ä¸»åç¨‹ä¸é€€å‡º
    await asyncio.Event().wait()

if __name__ == "__main__":
    asyncio.run(main())