import pvporcupine
import pyaudio
import struct
import configparser
from datetime import datetime

import asyncio
import threading
import time
from pathlib import Path
# æ¥è‡ªå‰é¢ç¤ºä¾‹
from voice_assistant.tasks.task_manager4 import AudioScheduler, PlayMusicTask
from voice_assistant.tasks.weather_task2 import WeatherTask
from voice_assistant.tasks.play_audio_task import PlayAudioTask
from voice_assistant.tasks.llm_task import LLMConversationTask
from voice_assistant.tasks.speak_task import SpeakTextTask


# nul parser
from voice_assistant.nlu.nlu import CommandParser


from voice_assistant.recognize_speech import recognize_speech

# config parser
config = configparser.ConfigParser()
# load config
config.read('../env/config.ini')

porcupine_access_key = config.get('listener', 'pvporcupine_access_key') # key

custom_keyword_franky_path = config.get('listener', 'custom_keyword_franky')

confirm_mp3_path = config.get('listener', 'confirm_mp3_path')


porcupine = pvporcupine.create(keyword_paths=[custom_keyword_franky_path],
                               keywords=["franky"],
                               access_key=porcupine_access_key,
                               sensitivities=[0.7])

pa = pyaudio.PyAudio()

audio_stream = pa.open(
    rate=porcupine.sample_rate,
    channels=1,
    format=pyaudio.paInt16,
    input=True,
    frames_per_buffer=porcupine.frame_length)

def wake_and_recognize(loop: asyncio.AbstractEventLoop, scheduler: AudioScheduler):
    print("Listening for 'picovoice'...")
    nlu_parser = CommandParser()

    in_chat_session = False
    chat_session_history = []

    try:
        while True:
            pcm = audio_stream.read(porcupine.frame_length, exception_on_overflow=False)
            pcm = struct.unpack_from("h" * porcupine.frame_length, pcm)

            result = porcupine.process(pcm)

            if result >= 0:

                # è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´
                now = datetime.now()
                # æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²
                formatted_date = now.strftime("%Y-%m-%d %H:%M:%S")
                print(f'ğŸ””{formatted_date} å”¤é†’è¯æ£€æµ‹åˆ°ï¼æ‰§è¡Œå”¤é†’åŠ¨ä½œ...')

                _was_playing = scheduler.audio_player.play_obj and scheduler.audio_player.play_obj.is_playing()
                print(f"_was_playing: {_was_playing}")

                confirm_mp3 = Path(confirm_mp3_path)
                loop.call_soon_threadsafe(
                    scheduler.enqueue,
                    PlayAudioTask(confirm_mp3, was_playing=_was_playing)
                )

                from voice_assistant.recognize_speech.recognize_speech import recoginze_speech
                recognized_command = recoginze_speech(audio_stream, timeout=3)
                print(f"ğŸ—£ï¸ è¯†åˆ«åˆ°: {recognized_command!r}")
                # 2) call NLU
                intent, params = nlu_parser.parse(recognized_command)
                print(f"ğŸ” è¯†åˆ«æ„å›¾ï¼šIntent={intent}, Params={params}")

                # è°ƒç”¨ä½ åŠ©æ‰‹çš„ä¸»é€»è¾‘æ¨¡å—
                # ç®€å•å‘½ä»¤è§£æ â€”â€” æ’­æ”¾éŸ³ä¹
                text = recognized_command
                if intent == "play_music":
                    # åœ¨ asyncio è°ƒåº¦å™¨ä¸­åˆ›å»ºä»»åŠ¡
                    # å®‰å…¨åœ°æŠŠ MusicTask åŠ å…¥ä¸»çº¿ç¨‹çš„ asyncio è°ƒåº¦å™¨
                    loop.call_soon_threadsafe(scheduler.enqueue, PlayMusicTask())
                elif intent == "pause_music":
                    # åœ¨ä¸»å¾ªç¯é‡Œåˆ›å»ºä¸€ä¸ª pause() çš„åç¨‹ä»»åŠ¡
                    # ç›´æ¥æš‚åœæ’­æ”¾å™¨
                    loop.call_soon_threadsafe(scheduler.pause_music)
                elif intent == "resume_music":
                    loop.call_soon_threadsafe(scheduler.resume_music)
                elif intent == "next_track":
                    loop.call_soon_threadsafe(scheduler.next_track)
                elif intent == "prev_track":
                    loop.call_soon_threadsafe(scheduler.prev_track)
                elif intent == "stop_music":
                    # åœæ‰ä»»åŠ¡å¹¶åœæ­¢æ’­æ”¾å™¨
                    loop.call_soon_threadsafe(scheduler.audio_player.pause_music)
                if intent == "chat_with_ai":
                    # æ„é€ å¯¹è¯å†å²
                    history = [{"role": "user", "content": recognized_command}]
                    # å°† LLM å¯¹è¯ä»»åŠ¡æ³¨å…¥
                    loop.call_soon_threadsafe(scheduler.enqueue, LLMConversationTask(history))
                elif intent == "weather":
                    # å°† WeatherTask åŠ å…¥è°ƒåº¦å™¨
                    was_playing = scheduler.audio_player.play_obj and scheduler.audio_player.play_obj.is_playing()
                    print(f"was_playing: {was_playing}")
                    loop.call_soon_threadsafe(
                        scheduler.enqueue,
                        WeatherTask(was_playing=was_playing)
                    )
                elif intent == "get_date":
                    # å°† WeatherTask åŠ å…¥è°ƒåº¦å™¨
                    loop.call_soon_threadsafe(
                        scheduler.enqueue,
                        SpeakTextTask(params['date_text'])
                    )
                elif intent == "get_time":
                    # å°† WeatherTask åŠ å…¥è°ƒåº¦å™¨
                    loop.call_soon_threadsafe(
                        scheduler.enqueue,
                        SpeakTextTask(params['time_text'])
                    )
                time.sleep(1)

    except KeyboardInterrupt:
        print("å…³é—­ä¸­...")

    finally:
        audio_stream.stop_stream()
        audio_stream.close()
        pa.terminate()
        porcupine.delete()


# === 5. å¯åŠ¨ ===
async def main():
    scheduler = AudioScheduler(mp3_dir=Path("../voice_assistant/mp3s"), loop_playlist=True)
    # å¯åŠ¨è°ƒåº¦å™¨å¾ªç¯
    asyncio.create_task(scheduler.loop())

    # è·å–å½“å‰äº‹ä»¶å¾ªç¯å¹¶ä¼ å…¥è¯†åˆ«çº¿ç¨‹
    loop = asyncio.get_running_loop()
    threading.Thread(target=wake_and_recognize, args=(loop, scheduler), daemon=True).start()

    # ä¸»åç¨‹ä¸é€€å‡º
    await asyncio.Event().wait()

if __name__ == "__main__":
    asyncio.run(main())